## Machine_Learning-Classification
**3/4 in Machine_Learning-Specialization————Classification**

<br /> <br />
---
### Course-Content 学习内容
--
* ** Linear Classifiers & Logistic Regression分类器和逻辑回归**

线性分类器是最实用的分类方法。 例如，在我们的情绪分析案例研究中，线性分类器将系数与句子中每个单词的计数相关联。
专注于一种特别有用的称为逻辑回归的线性分类器，除了允许您预测类外，还提供了与预测相关的概率。

Linear classifiers are amongst the most practical classification methods. For example, in our sentiment analysis case-study, a linear classifier associates a coefficient with the counts of each word in the sentence. focus on a particularly useful type of linear classifier called logistic regression, which, in addition to allowing you to predict a class, provides a probability associated with the prediction. These probabilities are extremely useful.

<br /> <br />

* **Decision Trees决策树**

决策树是现实世界中使用最广泛的分类技术之一。 这种方法非常直观，易于实现并提供可解释的预测。
decision trees are amongst the most widely used classification techniques in the real world. This method is extremely intuitive, simple to implement and provides interpretable predictions.

 <br /> <br />

* **Preventing Overfitting in Decision Trees决策树防过拟合技巧**

在所有机器学习技术中，决策树是最容易过度拟合的。 没有包括减轻这一挑战的方法，实际上并不可行。 在本单元中，通过各种可视化和调查，您将调查为什么决策树遭受重大过度配套问题。 使用奥卡姆剃刀的原则

Out of all machine learning techniques, decision trees are amongst the most prone to overfitting. No practical implementation is possible without including approaches that mitigate this challenge. In this module, through various visualizations and investigations, you will investigate why decision trees suffer from significant overfitting problems. Using the principle of Occam's razor
 <br /> <br />

* **Boosting**

有关机器学习的最令人兴奋的理论问题之一是简单的分类器是否可以组合成一个高度精确的集合。 在这个模块中，将首先定义整数分类器，其中多个模型对最佳预测进行投票。 然后，将探索一种称为AdaBoost的增强算法，它为提升分类器提供了一种很好的方法

One of the most exciting theoretical questions that have been asked about machine learning is whether simple classifiers can be combined into a highly accurate ensemble. 
In this module, will first define the ensemble classifier, where multiple models vote on the best prediction. You will then explore a boosting algorithm called AdaBoost, which provides a great approach for boosting classifiers
 <br /> <br />

* **Precision-Recall准确率和召回率**

在许多真实世界的设置中，准确性或错误不是分类的最佳质量指标。
In many real-world settings, accuracy or error are not the best quality metrics for classification.
 <br /> <br />
 
 * **Scaling to Huge Datasets & Online Learning大数据集和在线学习**

随着互联网的出现，社交媒体的增长和传感器在世界上的嵌入，我们的机器学习算法必须处理的数据量在过去十年中大大增长。 这种效果有时被称为“大数据”。开发一个称为随机梯度的梯度上升的方法，这在我们的算法的运行时间内提供了显着的加速。

With the advent of the internet, the growth of social media, and the embedding of sensors in the world, the magnitudes of data that our machine learning algorithms must handle have grown tremendously over the last decade. This effect is sometimes called "Big Data".develop a small modification of gradient ascent called stochastic gradient, which provides significant speedups in the running time of our algorithms.  

* For more information：go https://www.coursera.org/learn/ml-foundations
 <br />

## Author
[MingJun Li](https://github.com/littlewizardLI)

## License
[MIT license](https://github.com/littlewizardLI/LICENSE)
